# An unique identifier for the head node and workers of this cluster.
cluster_name: gpu

max_workers: 4
upscaling_speed: 10.0

docker:
    image: "rayproject/ray:latest-gpu"
    container_name: "ray_container"


# Cloud-provider specific configuration.
provider:
    type: aws
    region: us-west-2
    cache_stopped_nodes: False 

# How Ray will authenticate with newly launched nodes.
auth:
    ssh_user: ubuntu
#    ssh_private_key: /path/to/your/key.pem

# Tell the autoscaler the allowed node types and the resources they provide.
# The key is the name of the node type, which is just for debugging purposes.
# The node config specifies the launch config and physical instance type.
available_node_types:
    # CPU head node.
    ray.head.default:
        resources: {}
        node_config:
            InstanceType: m5.large
            ImageId: ami-0a2363a9cff180a64 # Deep Learning AMI (Ubuntu) Version 30
            # You can provision additional disk space with a conf as follows
            BlockDeviceMappings:
                - DeviceName: /dev/sda1
                  Ebs:
                      VolumeSize: 100
    # GPU workers.
    ray.worker.default:
        docker:
            worker_image: "rayproject/ray-ml:latest-gpu"
        min_workers: 1
        max_workers: 3
        node_config:
            InstanceType: g4dn.2xlarge 
            ImageId: ami-0a2363a9cff180a64 # Deep Learning AMI (Ubuntu) Version 30
#            Enable spot instances to save money. Note that too low of a max price may result in failure to request nodes
#            InstanceMarketOptions:
#                MarketType: spot
#                SpotOptions
#                  MaxPrice: "1.75"

# Specify the node type of the head node (as configured above).
head_node_type: ray.head.default

# List of shell commands to run to set up nodes.
# NOTE: rayproject/ray:latest has ray latest bundled
setup_commands:
  - pip install adaptdl_ray

# Custom commands that will be run on the head node after common setup.
head_setup_commands:
    - pip install boto3==1.4.8  # 1.4.8 adds InstanceMarketOptions

# Custom commands that will be run on worker nodes after common setup.
worker_setup_commands: []

# Command to start ray on the head node. You don't need to change this.
head_start_ray_commands:
    - ray stop
    - ulimit -n 65536; ray start --head --port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml

# Command to start ray on worker nodes. You don't need to change this.
worker_start_ray_commands:
    - ray stop
    - ulimit -n 65536; ray start --address=$RAY_HEAD_IP:6379 --object-manager-port=8076
